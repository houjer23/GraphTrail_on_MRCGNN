{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "# Load the tensor and map it to the CPU\n",
    "data = torch.load('data_o_new2.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Print the shape of the tensor\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRCGNN Revised Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.3.1\n",
      "  Downloading torch-2.3.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch==2.3.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch==2.3.1) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch==2.3.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch==2.3.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch==2.3.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch==2.3.1) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.3.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from sympy->torch==2.3.1) (1.3.0)\n",
      "Downloading torch-2.3.1-cp312-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "Successfully installed torch-2.3.1\n",
      "Requirement already satisfied: torch_geometric==2.6.1 in /Users/tyler/anaconda3/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (3.10.5)\n",
      "Requirement already satisfied: fsspec in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (3.1.4)\n",
      "Requirement already satisfied: numpy in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (3.1.2)\n",
      "Requirement already satisfied: requests in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/tyler/anaconda3/lib/python3.12/site-packages (from torch_geometric==2.6.1) (4.66.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric==2.6.1) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric==2.6.1) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric==2.6.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric==2.6.1) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric==2.6.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from aiohttp->torch_geometric==2.6.1) (1.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from jinja2->torch_geometric==2.6.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric==2.6.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric==2.6.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric==2.6.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tyler/anaconda3/lib/python3.12/site-packages (from requests->torch_geometric==2.6.1) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.3.1\n",
    "!pip install torch_geometric==2.6.1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.f_k = nn.Bilinear(32, 32, 1)\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "    def forward(self, c, h_pl, h_mi, s_bias1=None, s_bias2=None):\n",
    "        c_x = c.expand_as(h_pl)\n",
    "        sc_1 = self.f_k(h_pl, c_x)\n",
    "        sc_2 = self.f_k(h_mi, c_x)\n",
    "        if s_bias1 is not None:\n",
    "            sc_1 += s_bias1\n",
    "        if s_bias2 is not None:\n",
    "            sc_2 += s_bias2\n",
    "        logits = torch.cat((sc_1, sc_2), 1)\n",
    "        return logits\n",
    "\n",
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgReadout, self).__init__()\n",
    "    def forward(self, seq, msk=None):\n",
    "        if msk is None:\n",
    "            return torch.mean(seq, 0)\n",
    "        else:\n",
    "            msk = torch.unsqueeze(msk, -1)\n",
    "            return torch.sum(seq * msk, 0) / torch.sum(msk)\n",
    "\n",
    "class MRCGNN(nn.Module):\n",
    "    def __init__(self, feature, hidden1, hidden2, decoder1, dropout, zhongzi):\n",
    "        super(MRCGNN, self).__init__()\n",
    "\n",
    "        # RGCN layers for the main (data_o) branch\n",
    "        self.encoder_o1 = RGCNConv(feature, hidden1, num_relations=65)\n",
    "        self.encoder_o2 = RGCNConv(hidden1, hidden2, num_relations=65)\n",
    "\n",
    "        # Two-element parameter for layer attention\n",
    "        self.attt = nn.Parameter(torch.tensor([0.5, 0.5]))\n",
    "        self.disc = Discriminator(hidden2 * 2)\n",
    "        self.dropout = dropout\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.read = AvgReadout()\n",
    "        \n",
    "        # Final classifier: prediction solely from data_o branch.\n",
    "        # Each node's final representation is a concatenation of (hidden1 + hidden2).\n",
    "        # For a pair of entities, the dimension becomes 2*(hidden1+hidden2).\n",
    "        self.classifier = nn.Linear(2 * (hidden1 + hidden2), 65)\n",
    "\n",
    "        # We no longer load any pretrained features for skip connection.\n",
    "\n",
    "    def forward(self, data_o, data_s, data_a, idx):\n",
    "        # Process data_o branch\n",
    "        x_o, adj, e_type = data_o.x, data_o.edge_index, data_o.edge_type\n",
    "        e_type1 = data_a.edge_type\n",
    "        e_type = torch.tensor(e_type, dtype=torch.int64)\n",
    "        e_type1 = torch.tensor(e_type1, dtype=torch.int64)\n",
    "\n",
    "        # Main branch for prediction (data_o)\n",
    "        x1_o = F.relu(self.encoder_o1(x_o, adj, e_type))\n",
    "        x1_o = F.dropout(x1_o, self.dropout, training=self.training)\n",
    "        x2_o = self.encoder_o2(x1_o, adj, e_type)\n",
    "\n",
    "        # Contrastive learning branches (unused in prediction)\n",
    "        x_a = data_s.x\n",
    "        x1_o_a = F.relu(self.encoder_o1(x_a, adj, e_type))\n",
    "        x1_o_a = F.dropout(x1_o_a, self.dropout, training=self.training)\n",
    "        x2_o_a = self.encoder_o2(x1_o_a, adj, e_type)\n",
    "\n",
    "        x1_o_a_a = F.relu(self.encoder_o1(x_o, adj, e_type1))\n",
    "        x1_o_a_a = F.dropout(x1_o_a_a, self.dropout, training=self.training)\n",
    "        x2_o_a_a = self.encoder_o2(x1_o_a_a, adj, e_type1)\n",
    "\n",
    "        # Readout for contrastive learning\n",
    "        h_os = self.read(x2_o)\n",
    "        h_os = self.sigm(h_os)\n",
    "        ret_os = self.disc(h_os, x2_o, x2_o_a)\n",
    "        ret_os_a = self.disc(h_os, x2_o, x2_o_a_a)\n",
    "\n",
    "        # For final prediction, use only data_o branch:\n",
    "        final = torch.cat((self.attt[0] * x1_o, self.attt[1] * x2_o), dim=1)\n",
    "\n",
    "        a = [int(i) for i in list(idx[0])]\n",
    "        b = [int(i) for i in list(idx[1])]\n",
    "        aa = torch.tensor(a, dtype=torch.long)\n",
    "        bb = torch.tensor(b, dtype=torch.long)\n",
    "        entity1 = final[aa]\n",
    "        entity2 = final[bb]\n",
    "        concatenate = torch.cat((entity1, entity2), dim=1)\n",
    "        log = self.classifier(concatenate)\n",
    "\n",
    "        return log, ret_os, ret_os_a, x2_o\n",
    "\n",
    "    def predict(self, data_o, idx):\n",
    "        \"\"\"\n",
    "        New prediction method that uses only data_o and idx.\n",
    "        \"\"\"\n",
    "        x_o, adj, e_type = data_o.x, data_o.edge_index, data_o.edge_type\n",
    "        e_type = torch.tensor(e_type, dtype=torch.int64)\n",
    "        # Process the main branch\n",
    "        x1_o = F.relu(self.encoder_o1(x_o, adj, e_type))\n",
    "        x1_o = F.dropout(x1_o, self.dropout, training=self.training)\n",
    "        x2_o = self.encoder_o2(x1_o, adj, e_type)\n",
    "        final = torch.cat((self.attt[0] * x1_o, self.attt[1] * x2_o), dim=1)\n",
    "        \n",
    "        a = [int(i) for i in list(idx[0])]\n",
    "        b = [int(i) for i in list(idx[1])]\n",
    "        aa = torch.tensor(a, dtype=torch.long)\n",
    "        bb = torch.tensor(b, dtype=torch.long)\n",
    "        entity1 = final[aa]\n",
    "        entity2 = final[bb]\n",
    "        concatenate = torch.cat((entity1, entity2), dim=1)\n",
    "        log = self.classifier(concatenate)\n",
    "        return log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MRCGNN(\n",
       "  (encoder_o1): RGCNConv(128, 64, num_relations=65)\n",
       "  (encoder_o2): RGCNConv(64, 32, num_relations=65)\n",
       "  (disc): Discriminator(\n",
       "    (f_k): Bilinear(in1_features=32, in2_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (sigm): Sigmoid()\n",
       "  (read): AvgReadout()\n",
       "  (classifier): Linear(in_features=192, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MRCGNN(feature=128, hidden1=64, hidden2=32, decoder1=512, dropout=0.5, zhongzi=0)\n",
    "model.load_state_dict(torch.load(\"model_mrcgnn.pt\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_mrcgnn.pt\", map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data object: Data(x=[572, 128], edge_index=[2, 52112], edge_type=[52112])\n",
      "Number of unique ctree codes: 24\n",
      "Concept vector (frequency of each code):\n",
      "[522   5   4   1   9   9   1   1   2   1   1   1   1   1   3   1   1   1\n",
      "   1   1   1   1   1   2]\n",
      "Sample unique computation tree codes and frequencies:\n",
      "Code 0: 0-408-22-477-474-214-16-130-182-365-33-63-57-240-250-8-527-366-223-113-233-31-311-154-61-228-437-426-310-161-418-274-567-13-406-279-60-346-114-19-320-398-166-53-120-211-556-502-348-563-522-18-40-545-224-225-202-321-388-503-383-167-352-193-419-410-111-183-370-330-194-252-264-151-273-349-195-216-363-507-534-47-128-123-253-255-288-394-54-555-282-77-354-324-339-405-99-44-226-520-17-209-326-415-298-43-266-338-490-483-89-548-169-500-376-291-145-64-441-488-323-565-529-178-95-160-232-347-105-454-414-355-198-399-448-436-269-157-28-29-424-480-416-49-132-51-537-335-340-242-119-236-88-485-146-501-450-131-258-452-382-482-11-20-333-451-542-290-286-245-515-237-7-155-281-197-73-261-91-510-430-557-2-400-74-239-521-344-308-142-259-125-523-107-412-463-350-547-517-277-423-249-327-205-177-404-70-76-129-552-289-23-117-94-434-312-316-464-307-428-374-26-38-447-254-30-90-543-553-25-409-62-46-148-116-139-505-385-564-328-518-554-473-292-152-325-478-562-55-71-271-378-4-421-445-102-75-72-471-235-244-343-106-498-185-381-425-230-508-103-389-351-127-509-156-56-67-59-551-462-372-215-429-220-494-37-41-293-32-163-456-427-486-549-172-511-108-284-48-97-303-391-256-317-212-492-93-98-396-217-285-184-83-65-458-191-208-299-100-221-190-519-12-82-489-460-144-137-287-438-115-229-341-210-104-35-276-302-162-14-484-544-173-247-109-295-470-530-435-36-262-168-3-407-359-134-80-175-313-468-411-401-136-126-402-85-39-524-66-78-373-86-9-227-6-453-280-238-135-377-329-367-417-443-270-353-170-159-263-213-332-360-395-539-118-68-199-188-469-432-479-356-187-87-497-181-446-439-322-491-268-24-369-504-362-309-192-153-81-174-231-532-431-304-526-513-110-141-345-257-260-558-300-533-384-525-241-422-461-481-357-440-171-272-283-234-246-496-397-442-387-200-79-218-459-512-50-493-101-318-334-331-455-45-138-560-516-314-207-122-186-296-566-559-541-506-203-379-112-550-219-179-278-92-149-27-58-251-222-420-96-204-305-15-5-457-275-10-476-531-306-69-164-301-393-265-294-371-147-248-536-392-465-243-297-364-358-413-140-1-466-201-176-206-143-380-158-433-315-375-528-150-165-514-538-34-319-535-342-124-499-449-561-368-21-84-475-386-361-336-390-403-189-337-42-540-444-267-487-180-196-467-121-495-472-546-133-52\n",
      "Frequency: 522\n",
      "\n",
      "Code 1: 0-407-22-475-472-213-16-130-181-364-33-63-57-239-249-8-525-365-222-113-232-31-310-154-61-227-436-425-309-161-417-273-565-13-405-278-60-345-114-19-319-397-165-53-120-210-554-500-347-561-520-18-40-543-223-224-201-320-387-501-382-166-351-192-418-409-111-182-369-329-193-251-263-151-272-348-194-215-362-505-532-47-128-123-252-254-287-393-54-553-281-77-353-323-338-404-99-44-225-518-17-208-325-414-297-43-265-337-488-481-89-546-168-498-375-290-145-64-440-486-322-563-527-177-95-160-231-346-105-452-413-354-197-398-446-435-268-157-28-29-423-478-415-49-132-51-535-334-339-241-119-235-88-483-146-499-448-131-257-450-381-480-11-20-332-449-540-289-285-244-513-236-7-155-280-196-73-260-91-508-429-555-2-399-74-238-519-343-307-142-258-125-521-107-411-461-349-545-515-276-422-248-326-204-176-403-70-76-129-550-288-23-117-94-433-311-315-462-306-427-373-26-38-445-253-30-90-541-551-25-408-62-46-148-116-139-503-384-562-327-516-552-471-291-152-324-476-560-55-71-270-377-4-420-443-102-75-72-469-234-243-342-106-496-184-380-424-229-506-103-388-350-127-507-156-56-67-59-549-460-371-214-428-219-492-37-41-292-32-163-454-426-484-547-171-509-108-283-48-97-302-390-255-316-211-490-93-98-395-216-284-183-83-65-456-190-207-298-100-220-189-517-12-82-487-458-144-137-286-437-115-228-340-209-104-35-275-301-162-14-482-542-172-246-109-294-468-528-434-36-261-167-3-406-358-134-80-174-312-466-410-400-136-126-401-85-39-522-66-78-372-86-9-226-6-451-279-237-135-376-328-366-416-442-269-352-169-159-262-212-331-359-394-537-118-68-198-187-467-431-477-355-186-87-495-180-444-438-321-489-267-24-368-502-361-308-191-153-81-173-230-530-430-303-524-511-110-141-344-256-259-556-299-531-383-523-240-421-459-479-356-439-170-271-282-233-245-494-396-441-386-199-79-217-457-510-50-491-101-317-333-330-453-45-138-558-514-313-206-122-185-295-564-557-539-504-202-378-112-548-218-178-277-92-149-27-58-250-221-419-96-203-304-15-5-455-274-10-474-529-305-69-164-300-392-264-293-370-147-247-534-391-463-242-296-363-357-412-140-1-464-200-175-205-143-379-158-432-314-374-526-150-512-536-34-318-533-341-124-497-447-559-367-21-84-473-385-360-335-389-402-188-336-42-538-266-485-179-195-465-121-493-470-544-133-52\n",
      "Frequency: 5\n",
      "\n",
      "Code 2: 0\n",
      "Frequency: 4\n",
      "\n",
      "Code 3: 0-403-22-472-469-210-16-130-179-361-33-63-57-236-246-8-522-362-219-113-229-31-307-153-61-224-432-421-306-160-413-270-562-13-401-275-60-342-114-19-316-393-164-53-120-207-551-497-344-558-517-18-40-540-220-221-198-317-384-498-379-165-348-190-414-405-111-180-366-326-191-248-260-150-269-345-192-212-359-502-529-47-128-123-249-251-284-389-54-550-278-77-350-320-335-400-99-44-222-515-17-205-322-410-294-43-262-334-485-478-89-543-167-495-372-287-144-64-436-483-319-560-524-176-95-159-228-343-105-449-409-351-194-394-443-431-265-156-28-29-419-475-411-49-132-51-532-331-336-238-119-232-88-480-145-496-445-131-254-447-378-477-11-20-329-446-537-286-282-241-510-233-7-154-277-193-73-257-91-505-425-552-2-395-74-235-516-340-304-141-255-125-518-107-407-458-346-542-512-273-418-245-323-201-175-399-70-76-129-547-285-23-117-94-429-308-312-459-303-423-370-26-38-442-250-30-90-538-548-25-404-62-46-147-116-138-500-381-559-324-513-549-468-288-151-321-473-557-55-71-267-374-4-416-440-102-75-72-466-231-240-339-106-493-182-377-420-226-503-103-385-347-127-504-155-56-67-59-546-457-368-211-424-216-489-37-41-289-32-162-451-422-481-544-170-506-108-280-48-97-299-386-252-313-208-487-93-98-391-213-281-181-83-65-453-188-204-295-100-217-187-514-12-82-484-455-143-136-283-433-115-225-337-206-104-35-272-298-161-14-479-539-171-243-109-291-465-525-430-36-258-166-3-402-355-133-80-173-309-463-406-396-135-126-397-85-39-519-66-78-369-86-9-223-6-448-276-234-134-373-325-363-412-438-266-349-168-158-259-209-328-356-390-534-118-68-195-185-464-427-474-352-184-87-492-178-441-434-318-486-264-24-365-499-358-305-189-152-81-172-227-527-426-300-521-508-110-140-341-253-256-553-296-528-380-520-237-417-456-476-353-435-169-268-279-230-242-491-392-437-383-196-79-214-454-507-50-488-101-314-330-327-450-45-137-555-511-310-203-122-183-292-561-554-536-501-199-375-112-545-215-177-274-92-148-27-58-247-218-415-96-200-301-15-5-452-271-10-471-526-302-69-163-297-388-261-290-367-146-244-531-387-460-239-293-360-354-408-139-1-461-197-174-202-142-376-157-428-311-371-523-149-509-533-34-315-530-338-124-494-444-556-364-21-84-470-382-357-332-398-186-333-42-535-439-263-482-462-121-490-467-541-52\n",
      "Frequency: 1\n",
      "\n",
      "Code 4: 0-408-22-476-473-214-16-130-182-365-33-63-57-240-250-8-526-366-223-113-233-31-311-154-61-228-437-426-310-161-418-274-566-13-406-279-60-346-114-19-320-398-166-53-120-211-555-501-348-562-521-18-40-544-224-225-202-321-388-502-383-167-352-193-419-410-111-183-370-330-194-252-264-151-273-349-195-216-363-506-533-47-128-123-253-255-288-394-54-554-282-77-354-324-339-405-99-44-226-519-17-209-326-415-298-43-266-338-489-482-89-547-169-499-376-291-145-64-441-487-323-564-528-178-95-160-232-347-105-453-414-355-198-399-447-436-269-157-28-29-424-479-416-49-132-51-536-335-340-242-119-236-88-484-146-500-449-131-258-451-382-481-11-20-333-450-541-290-286-245-514-237-7-155-281-197-73-261-91-509-430-556-2-400-74-239-520-344-308-142-259-125-522-107-412-462-350-546-516-277-423-249-327-205-177-404-70-76-129-551-289-23-117-94-434-312-316-463-307-428-374-26-38-446-254-30-90-542-552-25-409-62-46-148-116-139-504-385-563-328-517-553-472-292-152-325-477-561-55-71-271-378-4-421-444-102-75-72-470-235-244-343-106-497-185-381-425-230-507-103-389-351-127-508-156-56-67-59-550-461-372-215-429-220-493-37-41-293-32-163-455-427-485-548-172-510-108-284-48-97-303-391-256-317-212-491-93-98-396-217-285-184-83-65-457-191-208-299-100-221-190-518-12-82-488-459-144-137-287-438-115-229-341-210-104-35-276-302-162-14-483-543-173-247-109-295-469-529-435-36-262-168-3-407-359-134-80-175-313-467-411-401-136-126-402-85-39-523-66-78-373-86-9-227-6-452-280-238-135-377-329-367-417-443-270-353-170-159-263-213-332-360-395-538-118-68-199-188-468-432-478-356-187-87-496-181-445-439-322-490-268-24-369-503-362-309-192-153-81-174-231-531-431-304-525-512-110-141-345-257-260-557-300-532-384-524-241-422-460-480-357-440-171-272-283-234-246-495-397-442-387-200-79-218-458-511-50-492-101-318-334-331-454-45-138-559-515-314-207-122-186-296-565-558-540-505-203-379-112-549-219-179-278-92-149-27-58-251-222-420-96-204-305-15-5-456-275-10-475-530-306-69-164-301-393-265-294-371-147-248-535-392-464-243-297-364-358-413-140-1-465-201-176-206-143-380-158-433-315-375-527-150-165-513-537-34-319-534-342-124-498-448-560-368-21-84-474-386-361-336-390-403-189-337-42-539-267-486-180-196-466-121-494-471-545-133-52\n",
      "Frequency: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.utils import k_hop_subgraph, to_networkx\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "##############################################################################\n",
    "# 1) LOAD YOUR DATA\n",
    "##############################################################################\n",
    "data = torch.load('data_o_new2.pt', map_location=torch.device('cpu'))\n",
    "print(\"Data object:\", data)\n",
    "# data is a single graph with data.x, data.edge_index, data.edge_type, etc.\n",
    "# e.g.: Data(x=[572, 128], edge_index=[2, 52112], edge_type=[52112])\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# 2) EXTRACT COMPUTATION TREES & CREATE CONCEPT VECTOR\n",
    "##############################################################################\n",
    "L = 3  # number of hops for each node’s subgraph (the “computation tree”)\n",
    "\n",
    "# We'll collect:\n",
    "#   node_ctree_codes[v] = string code for node v’s L-hop subgraph\n",
    "#   unique_ctree_codes   = dict {code_str -> assigned_id}\n",
    "node_ctree_codes = []\n",
    "unique_ctree_codes = {}\n",
    "\n",
    "def simple_dfs_code(G, root):\n",
    "    \"\"\"\n",
    "    Simple DFS code from a NetworkX graph G (treated as a tree),\n",
    "    starting at node 'root'. This is just a placeholder function:\n",
    "    you'd use a canonical labeling or something more robust in production.\n",
    "    \"\"\"\n",
    "    code = []\n",
    "    for n in nx.dfs_preorder_nodes(G, source=root):\n",
    "        code.append(str(n))\n",
    "    return \"-\".join(code)\n",
    "\n",
    "for v in range(data.num_nodes):\n",
    "    # Extract L-hop subgraph\n",
    "    subset, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "        node_idx=v,\n",
    "        num_hops=L,\n",
    "        edge_index=data.edge_index,\n",
    "        relabel_nodes=True\n",
    "    )\n",
    "    # Build a small Data object\n",
    "    sub_data = pyg.data.Data(\n",
    "        x=data.x[subset],\n",
    "        edge_index=sub_edge_index\n",
    "    )\n",
    "    # Convert to NetworkX\n",
    "    G_sub = to_networkx(sub_data, to_undirected=True)\n",
    "    \n",
    "    # In PyG’s relabel_nodes=True, the root node v becomes \"0\" in sub_data.\n",
    "    ctree_code = simple_dfs_code(G_sub, root=0)\n",
    "    node_ctree_codes.append(ctree_code)\n",
    "    if ctree_code not in unique_ctree_codes:\n",
    "        unique_ctree_codes[ctree_code] = len(unique_ctree_codes)\n",
    "\n",
    "# --- Step 2: Build the concept vector for the entire graph. ---\n",
    "# This vector is length (# unique ctree codes),\n",
    "# and entry i = count of nodes that have that code.\n",
    "concept_vector = np.zeros(len(unique_ctree_codes), dtype=int)\n",
    "for code in node_ctree_codes:\n",
    "    idx = unique_ctree_codes[code]\n",
    "    concept_vector[idx] += 1\n",
    "\n",
    "print(\"Number of unique ctree codes:\", len(unique_ctree_codes))\n",
    "print(\"Concept vector (frequency of each code):\")\n",
    "print(concept_vector)\n",
    "\n",
    "# Print out the first 5 unique computation tree codes and their frequencies:\n",
    "print(\"Sample unique computation tree codes and frequencies:\")\n",
    "for i, (code, idx) in enumerate(unique_ctree_codes.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    freq = concept_vector[idx]\n",
    "    print(f\"Code {idx}: {code}\")\n",
    "    print(f\"Frequency: {freq}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE \"REMOVE CONCEPTS\" FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_concepts_from_graph(data, node_ctree_codes, unique_ctree_codes, subset_of_codes):\n",
    "    \"\"\"\n",
    "    Prune out nodes whose L-hop code is not in 'subset_of_codes'.\n",
    "    Returns a new Data object and a mapping dict (old_index -> new_index).\n",
    "    \"\"\"\n",
    "    keep_nodes_list = []\n",
    "    for v in range(data.num_nodes):\n",
    "        if node_ctree_codes[v] in subset_of_codes:\n",
    "            keep_nodes_list.append(v)\n",
    "    \n",
    "    mapping = {old: new for new, old in enumerate(keep_nodes_list)}\n",
    "    \n",
    "    if not keep_nodes_list:\n",
    "        # No nodes remain; return empty data and empty mapping\n",
    "        new_data = pyg.data.Data(\n",
    "            x=torch.empty((0, data.x.shape[1])),\n",
    "            edge_index=torch.empty((2, 0), dtype=torch.long),\n",
    "            edge_type=torch.empty((0,), dtype=torch.long)\n",
    "        )\n",
    "        return new_data, mapping\n",
    "\n",
    "    keep_nodes = torch.tensor(keep_nodes_list, dtype=torch.long)\n",
    "    # Filter node features\n",
    "    x_new = data.x[keep_nodes]\n",
    "\n",
    "    # Filter edges and corresponding edge_type\n",
    "    edges = []\n",
    "    e_types = []\n",
    "    keep_set = set(keep_nodes_list)\n",
    "    for i in range(data.edge_index.size(1)):\n",
    "        src = data.edge_index[0, i].item()\n",
    "        dst = data.edge_index[1, i].item()\n",
    "        if (src in keep_set) and (dst in keep_set):\n",
    "            edges.append([src, dst])\n",
    "            e_types.append(data.edge_type[i])  # No .item() here\n",
    "    if edges:\n",
    "        edges = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        e_types = torch.tensor(e_types, dtype=torch.int64)\n",
    "    else:\n",
    "        edges = torch.empty((2,0), dtype=torch.long)\n",
    "        e_types = torch.empty((0,), dtype=torch.int64)\n",
    "    \n",
    "    # Relabel node IDs\n",
    "    edges = _relabel_edge_index(edges, keep_nodes)\n",
    "\n",
    "    new_data = pyg.data.Data(x=x_new, edge_index=edges, edge_type=e_types)\n",
    "    return new_data, mapping\n",
    "\n",
    "def _relabel_edge_index(edge_index, keep_nodes):\n",
    "    old_to_new = {old: i for i, old in enumerate(keep_nodes.tolist())}\n",
    "    new_edges = []\n",
    "    for i in range(edge_index.size(1)):\n",
    "        src_old = edge_index[0, i].item()\n",
    "        dst_old = edge_index[1, i].item()\n",
    "        new_edges.append([old_to_new[src_old], old_to_new[dst_old]])\n",
    "    if len(new_edges) == 0:\n",
    "        return torch.empty((2, 0), dtype=torch.long)\n",
    "    new_edges = torch.tensor(new_edges, dtype=torch.long).t().contiguous()\n",
    "    return new_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE A VALUE FUNCTION THAT RUNS MRCGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_function(model, data, idx,\n",
    "                   subset_of_codes, node_ctree_codes, unique_ctree_codes,\n",
    "                   target_class=None):\n",
    "    \"\"\"\n",
    "    1) Remove concepts not in 'subset_of_codes'\n",
    "    2) Update idx based on the new node numbering\n",
    "    3) Run model.predict() and return a scalar value.\n",
    "    \"\"\"\n",
    "    # 1) Prune the graph and get the mapping from old indices to new indices.\n",
    "    modified_data, mapping = remove_concepts_from_graph(\n",
    "        data, node_ctree_codes, unique_ctree_codes, subset_of_codes\n",
    "    )\n",
    "    \n",
    "    # 2) Update idx: For each index in idx, if it exists in mapping, use the new index.\n",
    "    new_src = []\n",
    "    new_dst = []\n",
    "    for src, dst in zip(idx[0].tolist(), idx[1].tolist()):\n",
    "        if src in mapping and dst in mapping:\n",
    "            new_src.append(mapping[src])\n",
    "            new_dst.append(mapping[dst])\n",
    "    if len(new_src) == 0 or len(new_dst) == 0:\n",
    "        return 0.0  # no valid pairs remain\n",
    "\n",
    "    new_idx = (torch.tensor(new_src, dtype=torch.long),\n",
    "               torch.tensor(new_dst, dtype=torch.long))\n",
    "    \n",
    "    # 3) Forward pass\n",
    "    with torch.no_grad():\n",
    "        out = model.predict(modified_data, new_idx)  # shape: [num_pairs, 65]\n",
    "        if out.shape[0] == 0:\n",
    "            return 0.0\n",
    "\n",
    "        if target_class is None:\n",
    "            # Use the predicted class for each pair and average the logit.\n",
    "            preds = out.argmax(dim=1)\n",
    "            chosen_logits = out[torch.arange(out.size(0)), preds]\n",
    "            val = chosen_logits.mean().item()\n",
    "        else:\n",
    "            chosen_logits = out[:, target_class]\n",
    "            val = chosen_logits.mean().item()\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAPLEY VALUES (SAMPLING APPROACH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shapley_values(model, data, idx,\n",
    "                   unique_ctree_codes, node_ctree_codes,\n",
    "                   target_class=None,\n",
    "                   num_samples=50):\n",
    "    \"\"\"\n",
    "    Approximate Shapley values via random permutations.\n",
    "    \"\"\"\n",
    "    concepts = list(unique_ctree_codes.keys())  # DFS-code strings\n",
    "    M = len(concepts)\n",
    "    shap = np.zeros(M, dtype=float)\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        perm = np.random.permutation(M)\n",
    "        current_subset = set()\n",
    "        old_val = value_function(\n",
    "            model, data, idx,\n",
    "            current_subset, node_ctree_codes, unique_ctree_codes,\n",
    "            target_class\n",
    "        )\n",
    "        for j in range(M):\n",
    "            c_idx = perm[j]\n",
    "            c_code = concepts[c_idx]\n",
    "            new_subset = current_subset.union({c_code})\n",
    "            new_val = value_function(\n",
    "                model, data, idx,\n",
    "                new_subset, node_ctree_codes, unique_ctree_codes,\n",
    "                target_class\n",
    "            )\n",
    "            shap[c_idx] += (new_val - old_val)\n",
    "            current_subset = new_subset\n",
    "            old_val = new_val\n",
    "\n",
    "    shap /= num_samples\n",
    "    code2shap = {concepts[i]: shap[i] for i in range(M)}\n",
    "    return code2shap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN SHAPLEY & DISPLAY RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shap_vals \u001b[38;5;241m=\u001b[39m shapley_values(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m      4\u001b[0m     idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[1;32m      5\u001b[0m     unique_ctree_codes\u001b[38;5;241m=\u001b[39munique_ctree_codes,\n\u001b[1;32m      6\u001b[0m     node_ctree_codes\u001b[38;5;241m=\u001b[39mnode_ctree_codes,\n\u001b[1;32m      7\u001b[0m     target_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# or an int specifying which class\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Sort Shapley results\u001b[39;00m\n\u001b[1;32m     12\u001b[0m sorted_shap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(shap_vals\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mshapley_values\u001b[0;34m(model, data, idx, unique_ctree_codes, node_ctree_codes, target_class, num_samples)\u001b[0m\n\u001b[1;32m     13\u001b[0m perm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(M)\n\u001b[1;32m     14\u001b[0m current_subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 15\u001b[0m old_val \u001b[38;5;241m=\u001b[39m value_function(\n\u001b[1;32m     16\u001b[0m     model, data, idx,\n\u001b[1;32m     17\u001b[0m     current_subset, node_ctree_codes, unique_ctree_codes,\n\u001b[1;32m     18\u001b[0m     target_class\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):\n\u001b[1;32m     21\u001b[0m     c_idx \u001b[38;5;241m=\u001b[39m perm[j]\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mvalue_function\u001b[0;34m(model, data, idx, subset_of_codes, node_ctree_codes, unique_ctree_codes, target_class)\u001b[0m\n\u001b[1;32m     15\u001b[0m new_src \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m new_dst \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src, dst \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(idx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), idx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m src \u001b[38;5;129;01min\u001b[39;00m mapping \u001b[38;5;129;01mand\u001b[39;00m dst \u001b[38;5;129;01min\u001b[39;00m mapping:\n\u001b[1;32m     19\u001b[0m         new_src\u001b[38;5;241m.\u001b[39mappend(mapping[src])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "shap_vals = shapley_values(\n",
    "    model=model,\n",
    "    data=data,\n",
    "    idx=idx,\n",
    "    unique_ctree_codes=unique_ctree_codes,\n",
    "    node_ctree_codes=node_ctree_codes,\n",
    "    target_class=None,  # or an int specifying which class\n",
    "    num_samples=50\n",
    ")\n",
    "\n",
    "# Sort Shapley results\n",
    "sorted_shap = sorted(shap_vals.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nTop-10 Concepts by Shapley Value:\")\n",
    "for c, val in sorted_shap[:10]:\n",
    "    print(f\"{c} => {val:.4f}\")\n",
    "\n",
    "# Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print(sorted_shap[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
